{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for Split Class\n",
    "\n",
    "- Evaluates the effect of preprocessy train test split function on model accuracy compared to sklearn train test split\n",
    "- Evaluates on 4 datasets\n",
    "    * iris\n",
    "    * boston\n",
    "    * breast_cancer\n",
    "    * diabetes\n",
    "- Using RandomForestClassifier() model on first 2 datasets\n",
    "- Using LinearRegression() model on other 2 datasets\n",
    "- Using r2_score of sklearn.metrics\n",
    "- Comparisons between sklearn and preprocessy based on accuracy and time for different test sizes have been indicated at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access preprocessy module. Required in .ipynb files\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_iris, load_boston, load_breast_cancer, load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessy.resampling import Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [None, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessy_eval(X, y, split, model):\n",
    "    X_train, X_test, y_train, y_test = Split().train_test_split(X, y, test_size=split)\n",
    "    preprocessy_test_size = None\n",
    "\n",
    "    if split:\n",
    "        preprocessy_test_size = split\n",
    "    else:\n",
    "        preprocessy_test_size = 1 / np.sqrt(len(X.columns))\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    return preprocessy_test_size, preds, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_eval(X, y, split, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=split, random_state=69\n",
    "    )\n",
    "    sklearn_test_size = None\n",
    "\n",
    "    if split:\n",
    "        sklearn_test_size = split\n",
    "    else:\n",
    "        sklearn_test_size = 0.25  # from sklearn docs\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return sklearn_test_size, preds, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(X, y, dataset, model):\n",
    "    print(f\"Dataset - {dataset}\\n\")\n",
    "    for split in splits:\n",
    "        start = time.time()\n",
    "        preprocessy_test_size, preprocessy_preds, preprocessy_y_test = preprocessy_eval(\n",
    "            X, y, split, model\n",
    "        )\n",
    "        end = time.time()\n",
    "        preprocessy_time = np.round(end - start,4)\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_test_size, sklearn_preds, sklearn_y_test = sklearn_eval(\n",
    "            X, y, split, model\n",
    "        )\n",
    "        end = time.time()\n",
    "        sklearn_time = np.round(end - start,4)\n",
    "        \n",
    "        preprocessy_accuracy =  np.round(\n",
    "                                classification_report(\n",
    "                                preprocessy_y_test, preprocessy_preds, output_dict=True\n",
    "                                )[\"accuracy\"],\n",
    "                                4)\n",
    "        sklearn_accuracy    =   np.round(classification_report(\n",
    "                                sklearn_y_test, sklearn_preds, output_dict=True\n",
    "                                )[\"accuracy\"],\n",
    "                                4)\n",
    "        \n",
    "        dt = {'Test_size': [preprocessy_test_size, sklearn_test_size],\n",
    "            'Accuracy': [preprocessy_accuracy, sklearn_accuracy],\n",
    "            'Time': [preprocessy_time, sklearn_time]\n",
    "        }\n",
    "        print(pd.DataFrame(dt,index=['Preprocessy','sklearn']))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval2(X, y, dataset, model):\n",
    "    print(f\"Dataset - {dataset}\\n\")\n",
    "    for split in splits:\n",
    "        start = time.time()\n",
    "        preprocessy_test_size, preprocessy_preds, preprocessy_y_test = preprocessy_eval(\n",
    "            X, y, split, model\n",
    "        )\n",
    "        end = time.time()\n",
    "        preprocessy_time = np.round(end - start,4)\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_test_size, sklearn_preds, sklearn_y_test = sklearn_eval(\n",
    "            X, y, split, model\n",
    "        )\n",
    "        end = time.time()\n",
    "        sklearn_time = np.round(end - start,4)\n",
    "\n",
    "        preprocessy_accuracy = np.round(r2_score(preprocessy_y_test, preprocessy_preds),4)\n",
    "        sklearn_accuracy = np.round(r2_score(sklearn_y_test, sklearn_preds),4)\n",
    "        \n",
    "        dt = {'Test_size': [preprocessy_test_size, sklearn_test_size],\n",
    "            'Accuracy': [preprocessy_accuracy, sklearn_accuracy],\n",
    "            'Time': [preprocessy_time, sklearn_time]\n",
    "        }\n",
    "        print(pd.DataFrame(dt,index=['Preprocessy','sklearn']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_iris():\n",
    "    model = RandomForestClassifier()\n",
    "    X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "    eval(X, y, \"iris\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_breast_cancer():\n",
    "    model = RandomForestClassifier()\n",
    "    X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "    eval(X, y, \"breast cancer\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_diabetes():\n",
    "    model = LinearRegression(fit_intercept=True, normalize=True, copy_X=True)\n",
    "    X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "    eval2(X, y, \"diabetes\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_boston():\n",
    "    model = LinearRegression(fit_intercept=True, normalize=True, copy_X=True)\n",
    "    dataset = load_boston()\n",
    "    X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "    y = pd.Series(dataset.target, name=\"Target\")\n",
    "    eval2(X, y, \"boston\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset - iris\n",
      "\n",
      "             Test_size  Accuracy    Time\n",
      "Preprocessy       0.50    0.9600  0.1257\n",
      "sklearn           0.25    0.9737  0.1237\n",
      "\n",
      "             Test_size  Accuracy    Time\n",
      "Preprocessy        0.2    0.9667  0.1516\n",
      "sklearn            0.2    0.9667  0.1307\n",
      "\n",
      "             Test_size  Accuracy    Time\n",
      "Preprocessy        0.3    0.9778  0.1417\n",
      "sklearn            0.3    0.9778  0.1506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset - breast cancer\n",
      "\n",
      "             Test_size  Accuracy    Time\n",
      "Preprocessy   0.182574    0.9515  0.2145\n",
      "sklearn       0.250000    0.9650  0.1855\n",
      "\n",
      "             Test_size  Accuracy    Time\n",
      "Preprocessy        0.2    0.9469  0.1845\n",
      "sklearn            0.2    0.9474  0.1805\n",
      "\n",
      "             Test_size  Accuracy    Time\n",
      "Preprocessy        0.3    0.9706  0.1575\n",
      "sklearn            0.3    0.9474  0.1636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset - diabetes\n\n             Test_size  Accuracy   Time\nPreprocessy   0.316228    0.4350  0.009\nsklearn       0.250000    0.4405  0.004\n\n             Test_size  Accuracy    Time\nPreprocessy        0.2    0.5065  0.0149\nsklearn            0.2    0.5145  0.0080\n\n             Test_size  Accuracy   Time\nPreprocessy        0.3    0.4482  0.011\nsklearn            0.3    0.4509  0.004\n\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset - boston\n\n             Test_size  Accuracy   Time\nPreprocessy    0.27735    0.6891  0.009\nsklearn        0.25000    0.6722  0.007\n\n             Test_size  Accuracy    Time\nPreprocessy        0.2    0.6752  0.0119\nsklearn            0.2    0.6747  0.0060\n\n             Test_size  Accuracy   Time\nPreprocessy        0.3    0.6755  0.006\nsklearn            0.3    0.6927  0.004\n\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd01e915f0a29dc84041eaeb02b7b1a21c440e37a87b61d44d5e84a515737dc82bc",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
