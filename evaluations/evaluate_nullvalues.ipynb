{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd01e915f0a29dc84041eaeb02b7b1a21c440e37a87b61d44d5e84a515737dc82bc",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Evaluation for NullValuesHandler Class\n",
    "\n",
    "- Evaluates the effect of preprocessy execute function on model accuracy compared to sklearn\n",
    "- Evaluates on 1 dataset\n",
    "    * Melbourne Housing Snapshot\n",
    "- Considering a standard test size of 0.3 for all 3 cases i.e.\n",
    "    * Dropping columns with null values\n",
    "    * Filling null values with mean\n",
    "    * Filling null values with mean considering values which were originally missing\n",
    "- Using RandomForestRegressor() model\n",
    "- Using r2_score of sklearn.metrics\n",
    "- Comparisons between sklearn and preprocessy based on accuracy and time have been indicated at the end"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access preprocessy module. Required in .ipynb files\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_iris, load_boston, load_breast_cancer, load_diabetes\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error,classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessy.handlenullvalues import NullValuesHandler\n",
    "from preprocessy.resampling import Split\n",
    "\n",
    "np.random.seed(101)"
   ]
  },
  {
   "source": [
    "## Melbourne Housing Snapshot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Suburb           Address  Rooms Type      Price Method SellerG  \\\n",
       "0  Abbotsford      85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "1  Abbotsford   25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "2  Abbotsford      5 Charles St      3    h  1465000.0     SP  Biggin   \n",
       "3  Abbotsford  40 Federation La      3    h   850000.0     PI  Biggin   \n",
       "4  Abbotsford       55a Park St      4    h  1600000.0     VB  Nelson   \n",
       "\n",
       "        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
       "1  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
       "2  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n",
       "3  4/03/2017       2.5    3067.0  ...       2.0  1.0      94.0           NaN   \n",
       "4  4/06/2016       2.5    3067.0  ...       1.0  2.0     120.0         142.0   \n",
       "\n",
       "   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n",
       "0        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n",
       "1     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n",
       "2     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n",
       "3        NaN        Yarra  -37.7969    144.9969  Northern Metropolitan   \n",
       "4     2014.0        Yarra  -37.8072    144.9941  Northern Metropolitan   \n",
       "\n",
       "  Propertycount  \n",
       "0        4019.0  \n",
       "1        4019.0  \n",
       "2        4019.0  \n",
       "3        4019.0  \n",
       "4        4019.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Suburb</th>\n      <th>Address</th>\n      <th>Rooms</th>\n      <th>Type</th>\n      <th>Price</th>\n      <th>Method</th>\n      <th>SellerG</th>\n      <th>Date</th>\n      <th>Distance</th>\n      <th>Postcode</th>\n      <th>...</th>\n      <th>Bathroom</th>\n      <th>Car</th>\n      <th>Landsize</th>\n      <th>BuildingArea</th>\n      <th>YearBuilt</th>\n      <th>CouncilArea</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n      <th>Regionname</th>\n      <th>Propertycount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abbotsford</td>\n      <td>85 Turner St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>1480000.0</td>\n      <td>S</td>\n      <td>Biggin</td>\n      <td>3/12/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>202.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra</td>\n      <td>-37.7996</td>\n      <td>144.9984</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abbotsford</td>\n      <td>25 Bloomburg St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>1035000.0</td>\n      <td>S</td>\n      <td>Biggin</td>\n      <td>4/02/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>156.0</td>\n      <td>79.0</td>\n      <td>1900.0</td>\n      <td>Yarra</td>\n      <td>-37.8079</td>\n      <td>144.9934</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abbotsford</td>\n      <td>5 Charles St</td>\n      <td>3</td>\n      <td>h</td>\n      <td>1465000.0</td>\n      <td>SP</td>\n      <td>Biggin</td>\n      <td>4/03/2017</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>134.0</td>\n      <td>150.0</td>\n      <td>1900.0</td>\n      <td>Yarra</td>\n      <td>-37.8093</td>\n      <td>144.9944</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abbotsford</td>\n      <td>40 Federation La</td>\n      <td>3</td>\n      <td>h</td>\n      <td>850000.0</td>\n      <td>PI</td>\n      <td>Biggin</td>\n      <td>4/03/2017</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra</td>\n      <td>-37.7969</td>\n      <td>144.9969</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abbotsford</td>\n      <td>55a Park St</td>\n      <td>4</td>\n      <td>h</td>\n      <td>1600000.0</td>\n      <td>VB</td>\n      <td>Nelson</td>\n      <td>4/06/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>120.0</td>\n      <td>142.0</td>\n      <td>2014.0</td>\n      <td>Yarra</td>\n      <td>-37.8072</td>\n      <td>144.9941</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "melb_data = pd.read_csv('../datasets/handling_null_values/melb_data.csv')\n",
    "melb_data_copy1 = melb_data\n",
    "melb_data_copy2 = melb_data\n",
    "\n",
    "dtf_1 = pd.DataFrame(columns = ['Accuracy', 'Time'])\n",
    "dtf_2 = pd.DataFrame(columns = ['Accuracy', 'Time'])\n",
    "dtf_3 = pd.DataFrame(columns = ['Accuracy', 'Time'])\n",
    "\n",
    "melb_data.head()"
   ]
  },
  {
   "source": [
    "### No of columns with null values in Original Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "melb_data.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BuildingArea    6450\n",
       "YearBuilt       5375\n",
       "CouncilArea     1369\n",
       "Car               62\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "missing_val_cnt_per_column = melb_data.isnull().sum().sort_values(ascending=False)[:4]\n",
    "total_val = np.product(melb_data.shape)\n",
    "perc = 100*(missing_val_cnt_per_column.sum())/total_val\n",
    "\n",
    "missing_val_cnt_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "missing_val_cnt: 13256 \ntotal_val      : 285180\nperc           : 4.648292306613367\n"
     ]
    }
   ],
   "source": [
    "print(f\"missing_val_cnt: {missing_val_cnt_per_column.sum()} \")\n",
    "print(f\"total_val      : {total_val}\")\n",
    "print(f\"perc           : {perc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider Price as Target property and others as Predictors \n",
    "melb_target = melb_data.Price\n",
    "\n",
    "melb_predictors = melb_data.drop(['Price'], axis=1)\n",
    "melb_numeric_predictors = melb_predictors.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "source": [
    "## Using sklearn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_score_dataset(sklearn_X_train, sklearn_X_test, sklearn_y_train, sklearn_y_test):\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(sklearn_X_train, sklearn_y_train)\n",
    "    sklearn_preds = model.predict(sklearn_X_test)\n",
    "\n",
    "    \n",
    "    sklearn_accuracy = np.round(r2_score(sklearn_y_test, sklearn_preds),4)\n",
    "    return sklearn_accuracy"
   ]
  },
  {
   "source": [
    "### Dropping columns with null values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(melb_numeric_predictors, \n",
    "                                                    melb_target,\n",
    "                                                    train_size=0.7, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "                                                    \n",
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_test  = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "acc = sklearn_score_dataset(reduced_X_train, reduced_X_test, y_train, y_test)\n",
    "\n",
    "end = time.time()\n",
    "sklearn_time = np.round(end - start,4)\n",
    "\n",
    "dtf_1.loc['sklearn'] = [acc, sklearn_time]"
   ]
  },
  {
   "source": [
    "### Imputation by default fills in the missing value with the mean value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "\n",
    "acc = sklearn_score_dataset(imputed_X_train, imputed_X_test, y_train, y_test)\n",
    "\n",
    "end = time.time()\n",
    "sklearn_time = np.round(end - start,4)\n",
    "\n",
    "dtf_2.loc['sklearn'] = [acc, sklearn_time]"
   ]
  },
  {
   "source": [
    "### Model can make better predictions by considering which values were originally missing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X_train_plus = X_train.copy()\n",
    "imputed_X_test_plus = X_test.copy()\n",
    "\n",
    "cols_with_missing = (col for col in X_train.columns if X_train[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull()\n",
    "    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "start = time.time()\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "\n",
    "imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\n",
    "imputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n",
    "\n",
    "acc= sklearn_score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test)\n",
    "\n",
    "end = time.time()\n",
    "sklearn_time = np.round(end - start,4)\n",
    "\n",
    "dtf_3.loc['sklearn'] = [acc, sklearn_time]"
   ]
  },
  {
   "source": [
    "## Using preprocessy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Car', 'BuildingArea', 'YearBuilt', 'CouncilArea']"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "cols_with_missing = [col for col in melb_data_copy2.columns if melb_data_copy2[col].isnull().any()]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessy_score_dataset(params):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    NullValuesHandler().execute(params)\n",
    "\n",
    "        # print(f\"No of Columns with Null values after execute: {params[\"df\"].isnull().any().sum()}\")\n",
    "        # missing_val_cnt_per_column = params[\"df\"].isnull().sum().sort_values(ascending=False)[:1]\n",
    "        # total_val = np.product(melb_data.shape)\n",
    "        # perc = 100*(missing_val_cnt_per_column.sum())/total_val\n",
    "\n",
    "        # print(f\"missing_val_cnt: {missing_val_cnt_per_column.sum()} \")\n",
    "        # print(f\"total_val: {total_val}\")\n",
    "        # print(f\"perc: {perc}\")\n",
    "\n",
    "    melb_target = params[\"df\"].Price\n",
    "    melb_predictors = params[\"df\"].drop(['Price'], axis=1)\n",
    "    melb_numeric_predictors = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "    par = {\"X\": melb_numeric_predictors, \"y\":  melb_target, \"test_size\": 0.3}\n",
    "    \n",
    "\n",
    "    Split().train_test_split(par)\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(par[\"X_train\"], par[\"y_train\"])\n",
    "    preprocessy_preds = model.predict(par[\"X_test\"])\n",
    "\n",
    "    end=time.time()\n",
    "    preprocessy_time = np.round(end - start,4)\n",
    "    \n",
    "    preprocessy_accuracy = np.round(r2_score(par[\"y_test\"], preprocessy_preds),4)\n",
    "    return preprocessy_accuracy, preprocessy_time"
   ]
  },
  {
   "source": [
    "## Using preprocessy\n",
    "- Dropping cloumns with null values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in melb_data_copy2.columns if melb_data_copy2[col].isnull().any()]\n",
    "\n",
    "params = {\"df\": melb_data_copy2, \"drop\": True, \"column_list\": cols_with_missing}\n",
    "acc, t = preprocessy_score_dataset(params)\n",
    "\n",
    "dtf_1.loc['Preprocessy'] = [acc, t]"
   ]
  },
  {
   "source": [
    "## Using preprocessy for imputation\n",
    "- filling missing values with mean"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"df\": melb_data_copy1, \"fill_missing\":  \"mean\"}\n",
    "\n",
    "acc, t = preprocessy_score_dataset(params)\n",
    "\n",
    "dtf_2.loc['Preprocessy'] = [acc, t]"
   ]
  },
  {
   "source": [
    "## Using preprocessy for imputation\n",
    "- filling missing values with mean and improving model by considering values whcih were originally missing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = (col for col in melb_data.columns if melb_data[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    melb_data[col + '_was_missing'] = melb_data[col].isnull()\n",
    "\n",
    "params = {\"df\": melb_data, \"fill_missing\":  \"mean\"}\n",
    "\n",
    "acc, t = preprocessy_score_dataset(params)\n",
    "\n",
    "dtf_3.loc['Preprocessy'] = [acc, t]"
   ]
  },
  {
   "source": [
    "## Comparison for case where we drop columns with null values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Accuracy    Time\n",
       "sklearn        0.7410  4.2711\n",
       "Preprocessy    0.7768  3.5912"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sklearn</th>\n      <td>0.7410</td>\n      <td>4.2711</td>\n    </tr>\n    <tr>\n      <th>Preprocessy</th>\n      <td>0.7768</td>\n      <td>3.5912</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "dtf_1"
   ]
  },
  {
   "source": [
    "## Comparison when Imputation without tracking is done"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Accuracy    Time\n",
       "sklearn        0.7658  5.2105\n",
       "Preprocessy    0.7892  5.0117"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sklearn</th>\n      <td>0.7658</td>\n      <td>5.2105</td>\n    </tr>\n    <tr>\n      <th>Preprocessy</th>\n      <td>0.7892</td>\n      <td>5.0117</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "dtf_2"
   ]
  },
  {
   "source": [
    "## Comparison when Imputation is done while tracking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Accuracy    Time\n",
       "sklearn        0.7661  4.7758\n",
       "Preprocessy    0.7914  5.1065"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sklearn</th>\n      <td>0.7661</td>\n      <td>4.7758</td>\n    </tr>\n    <tr>\n      <th>Preprocessy</th>\n      <td>0.7914</td>\n      <td>5.1065</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "dtf_3"
   ]
  }
 ]
}
